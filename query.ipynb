{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pdfquery\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path for input and output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = './test'\n",
    "output_file = 'output.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values inside the text box, [76.54, 347.551, 92.108, 354.511] in the snippet refers the “Left, Bottom, Right, Top” coordinates of the text box. You can think about the pdf page in terms of X-Y coordinates. The X-axis spans the width of the PDF page and the Y-axis spans the height of the page. Every element has its bounds defined by a bounding box which consists of 4 coordinates. These coordinates (X0, Y0, X1, Y1) represent left, bottom, right and top of the text box, which would give us the location of data we are interested in the PDF page.\n",
    "\n",
    "Using the textbox coordinates from the XML file, we can extract each piece of relevant information individually using their corresponding text box coordinates, and then combined all scraped information into single observation. In the following, we write a function to use “pdf.pq(‘LTTextLineHorizontal:overlaps_bbox(“#, #, #, #”)’).text()” to extract the data inside each textbox, then use pandas to construct a dataframe. More info at https://towardsdatascience.com/scrape-data-from-pdf-files-using-python-and-pdfquery-d033721c3b28\n",
    "BTW this is built just for BTECH data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfscrape(pdf):\n",
    "    # Extract just the ID from the box of name & id\n",
    "    institute_id = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"10.0, 524.137, 276.13, 533.137\")').text()\n",
    "    # Extact just the Title from the box of name & id\n",
    "    institute_name = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"10.0, 524.137, 276.13, 533.137\")').text()\n",
    "    year = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"426.0, 168.551, 451.683, 175.551\")').text()\n",
    "    no_of_mean_package = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"668.8, 151.0, 751.4, 182.0\")').text()\n",
    "    graduating_in_stipulated_time = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"508.6, 168.551, 520.276, 175.551\")').text()\n",
    "    placed_in_the_year = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"591.2, 168.551, 602.876, 175.551\")').text()\n",
    "    no_of_higher_edu = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"756.4, 168.551, 768.076, 175.551\")').text()\n",
    "    college_tier = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"668.8, 151.0, 751.4, 182.0\")').text()\n",
    "    no_of_male_students = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"76.54, 347.551, 92.108, 354.551\")').text()\n",
    "    no_of_female_students = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"140.08, 347.551, 151.756, 354.551\")').text()\n",
    "    total_students = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"203.62, 347.551, 219.188, 354.551\")').text()\n",
    "\n",
    "    # Extra Data\n",
    "    previous_year = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"426.0, 192.551, 451.683, 199.551\")').text()\n",
    "    second_to_last = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"426.0, 209.551, 451.683, 216.551\")').text()\n",
    "    previous_year_mean_package = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"673.8, 192.551, 736.842, 199.551\")').text()\n",
    "    second_to_last_mean_package = pdf.pq(\n",
    "        'LTTextLineHorizontal:overlaps_bbox(\"673.8, 209.551, 744.227, 216.551\")').text()\n",
    "\n",
    "    # Split text\n",
    "    institute_id = extract_id_from_xml(institute_id)\n",
    "    institute_name = extract_title_from_xml(institute_name)\n",
    "\n",
    "    # To determine the college tier on the basis of mean package\n",
    "    college_tier = determine_tier(no_of_mean_package)\n",
    "    \n",
    "    # Combine all relevant information into a single observation\n",
    "    page = pd.DataFrame({\n",
    "        'institute_id': institute_id,\n",
    "        'institute_name': institute_name,\n",
    "        'year': year,\n",
    "        'no_of_mean_package': no_of_mean_package,\n",
    "        'college_tier': college_tier,\n",
    "        'graduating_in_stipulated_time': graduating_in_stipulated_time,\n",
    "        'placed_in_the_year': placed_in_the_year,\n",
    "        'no_of_higher_edu': no_of_higher_edu,\n",
    "        'no_of_male_students': no_of_male_students,\n",
    "        'no_of_female_students': no_of_female_students,\n",
    "        'total_students':  total_students,\n",
    "        'source_pdf': f\"https://www.nirfindia.org/nirfpdfcdn/2022/pdf/Engineering/{institute_id}.pdf\",\n",
    "        # Extra Data\n",
    "        'previous_year':  previous_year,\n",
    "        'second_to_last': second_to_last,\n",
    "        'previous_year_mean_package': previous_year_mean_package,\n",
    "        'second_to_last_mean_package': second_to_last_mean_package\n",
    "    }, index=[0])\n",
    "    return page\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To differentiate id from name & generating tier on the basis of mean pakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_from_xml(xml_text):\n",
    "    # Extract the id without the institute name\n",
    "    match = re.search(r'\\[(.*?)\\]', xml_text)\n",
    "    if match:\n",
    "        value = match.group(1)\n",
    "        return value\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extract_title_from_xml(xml_text):\n",
    "    # Extract the institute name without the ID\n",
    "    match = re.search(r'Institute Name: (.*?) \\[', xml_text)\n",
    "    if match:\n",
    "        value = match.group(1)\n",
    "        return value.strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def determine_tier(mean_package):\n",
    "    if mean_package:\n",
    "        mean_package = extract_numeric_value(mean_package)\n",
    "        # Deciding college tier on the basis on mean package\n",
    "        if mean_package:\n",
    "            mean_package = float(mean_package)\n",
    "            if mean_package > 1000000:\n",
    "                return '1'\n",
    "            elif mean_package > 500000:\n",
    "                return '2'\n",
    "            else:\n",
    "                return '3'\n",
    "    return 'err'\n",
    "\n",
    "\n",
    "def extract_numeric_value(value):\n",
    "    # Remove non-numeric characters from the value\n",
    "    value = re.sub('[^0-9.]', '', value)\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over PDF files in the folder\n",
    "for filename in os.listdir(input_folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(input_folder_path, filename)\n",
    "\n",
    "        # Extract institute ID from the filename\n",
    "        institute_id = os.path.splitext(filename)[0]\n",
    "        # Converting PDF into an Extensible Markup Language (XML), which includes data and metadata of a given PDF page\n",
    "        pdf = pdfquery.PDFQuery(file_path)\n",
    "        pdf.load()\n",
    "        # ('pdfXML.txt', pretty_print=True) is a performance bottleneck when scraping large number of pdfs, remove it after allocating the coordinates\n",
    "        pdf.tree.write('pdfXML.txt')\n",
    "\n",
    "        pagecount = pdf.doc.catalog['Pages'].resolve()['Count']\n",
    "        master = pd.DataFrame()\n",
    "\n",
    "        for p in range(pagecount):\n",
    "            pdf.load(p)\n",
    "            page = pdfscrape(pdf)\n",
    "            master = pd.concat([master, page], ignore_index=True)\n",
    "\n",
    "        # Save to output.csv without leaving lines between them\n",
    "        with open(output_file, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if f.tell() == 0:\n",
    "                writer.writerow(master.columns)\n",
    "            writer.writerow(master.values.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
